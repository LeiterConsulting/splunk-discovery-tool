# Changelog

All notable changes to the Splunk Discovery Tool will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.1.0] - TBD (In Development)

### üß© V2 Workspace & Summarization UX Hardening

#### Added
- **V2 Workspace Surfaces (UI + API integration)**
  - Unified static top bar with Mission / Intelligence / Artifacts workflow tabs
  - Intelligence workspace bindings to `/api/discovery/dashboard`, `/api/discovery/compare`, `/api/discovery/runbook`, and `/api/v2/intelligence`
  - Artifacts workspace bindings to `/api/v2/artifacts` with V2-only artifact handling

- **Summarization Context Enrichment** (`/summarize-session`)
  - Environment extraction for indexes, sourcetypes, and hosts from V2 finding ledger
  - Environment-aware SPL query anchoring and evidence tagging
  - Context-engine fallback generation for both SPL queries and admin tasks
  - Expanded V2 payload surfaces (`trend_signals`, `risk_register`, `recursive_investigations`, `vulnerability_hypotheses`)

#### Changed
- **Header Architecture**
  - Removed legacy ‚ÄúMission Control‚Äù title block
  - Merged tab controls and action buttons into the top static header layout
  - Reworked tab actions to trigger real workspace state transitions and refreshes

- **Generated Reports/Artifacts Sidebar Behavior**
  - Refined session row spacing and indentation
  - Added clipping + min-width protections to prevent content overflow
  - Improved action button stacking for constrained widths

- **Summary Modal Progress Semantics**
  - Normalized stage mapping to include `creating_summary`
  - Added monotonic progress behavior during polling updates

#### Fixed
- **Dark Mode Readability**
  - Corrected compile/progress screen contrast in summary modal
  - Improved dark styling for SPL query and admin task tabs
  - Updated discovery log card rendering for phase/success/error/warning/info/rate-limit/completion states
  - Updated contrast for ‚ÄúSave LLM Credential‚Äù and ‚ÄúSave MCP Configuration‚Äù modals in dark theme

- **Provider-Agnostic LLM Configuration & Testing**
  - Normalized provider handling for `openai`, `azure`, `anthropic`, `gemini`, and `custom`
  - Updated `/api/llm/list-models` and `/api/llm/test-connection` to provider-aware behavior
  - Added custom endpoint candidate-path fallback for base URLs such as `/v1`

- **Summarization Error Handling**
  - Added missing `Tuple` typing import causing summarize-time runtime failure
  - Hardened client-side summary fetch parsing for non-JSON 500 responses
  - Improved surfaced error messages for failed summary requests

### üöÄ Phase 1: Resilience & Health Monitoring (CRITICAL)

#### Added
- **LLM Health Monitoring System** (`llm/health_monitor.py`)
  - Continuous endpoint health tracking with rolling metrics (last 100 requests)
  - Response time monitoring (average + 95th percentile)
  - Error rate tracking with health status (healthy/degraded/unhealthy)
  - Automatic recommendations for timeout and token limits
  - Consecutive failure detection (10+ failures = refuse requests)
  
- **Adaptive Timeout Management**
  - Dynamic timeout calculation based on endpoint health + payload size
  - Payload-aware timeouts (accounts for token count)
  - Error-rate adaptive buffer (higher errors = more buffer)
  - Range: 10-120 seconds (clamped to reasonable bounds)
  
- **Hung Request Detection**
  - Monitors requests for progress (30s no-progress = hung)
  - Automatic cancellation of stuck requests
  - Request ID tracking with timestamps
  - Clean timeout error messages
  
- **Payload Size Adaptation**
  - Intelligent message truncation based on endpoint health
  - Healthy: Full payload (100%)
  - Degraded: Reduced payload (70%)
  - Unhealthy: Aggressive reduction (50%)
  - System messages always preserved
  - Most recent messages prioritized
  
- **Enhanced CustomLLMClient**
  - Integrated health monitoring into sync request path
  - Pre-request health checks (refuse if 10+ consecutive failures)
  - Adaptive timeout per request
  - Automatic payload adaptation
  - Success/failure recording with metrics
  - Detailed health logging

- **Health Metrics API**
  - New endpoint: `GET /api/llm/health`
  - Returns per-endpoint health metrics

#### Testing
- ‚úÖ **Unit Test Scope**: Core health-monitoring behaviors validated
  - Health status transitions
  - Adaptive timeout calculation
  - Payload size adaptation
  - Hung request detection
  - Consecutive failure handling
  - Retry delay calculation
- ‚ö†Ô∏è **Integration Test Scope**: Partial pass with known mock-environment limits
  - HTTP 503 handling ‚úÖ
  - Timeout handling ‚ö†Ô∏è (needs mock server fixes)
  - Slow endpoint handling ‚ö†Ô∏è (needs mock server fixes)
  - Random failures ‚úÖ
  - High load ‚úÖ
  - Oversized payload ‚ö†Ô∏è (needs mock server fixes)
  - Summary statistics (healthy/degraded/unhealthy counts)
  - Exposed metrics:
    - Status, avg/p95 response time, error rate
    - Success/failure counts, timeout count
    - Last success/failure timestamps
    - Recommended timeout and max_tokens
    - Consecutive failures, uptime percentage

#### Changed
- CustomLLMClient now uses health-aware request handling
- Request timeouts are now adaptive (10-120s) instead of fixed 120s
- Message payloads automatically adapt to endpoint health
- All LLM requests now tracked for health metrics

#### Intelligence Improvements
- **Chat Agent**: 95/100 ‚Üí 98/100 (+3 points)
  - Resilience: 13 ‚Üí 15 (+2) - Health monitoring, hung detection
  - Adaptivity: 19 ‚Üí 20 (+1) - Endpoint-aware behavior
  - Token Efficiency: 14 ‚Üí 15 (+1) - Payload adaptation

### üéØ Phase 2: Adaptive Discovery (Planned)
- AI-driven discovery planning
- Context-aware MCP call selection
- Early termination logic
- Anomaly detection & deep-dive

### üîÅ Phase 3: Iterative Summarization (Planned)
- Multi-pass analysis with quality gates
- Gap detection and filling
- Self-assessment integration

### üèóÔ∏è Phase 4: Unified Agentic Framework (Planned)
- Shared agentic loop infrastructure
- Common quality assessment
- Unified error handling

---

## [1.0.0] - 2025-10-31

### üéâ Initial Release

First production-ready release of the Splunk Discovery Tool with AI-powered admin assistance.

### Added

#### Core Features
- **AI-Powered Admin Chat**: Natural language Splunk administration with intelligent SPL query generation
- **Multi-Turn Reasoning**: Automatic query refinement with quality validation (0-100 scale)
- **Smart Convergence Detection**: Prevents infinite loops while allowing data quality improvements
- **Discovery Engine**: Automated Splunk environment scanning via MCP protocol
- **Real-Time WebSocket**: Live updates for discovery progress and chat interactions

#### Configuration & Security
- **Encrypted Configuration**: Fernet encryption for all credentials (no plaintext storage)
- **Web-Based Settings Panel**: Complete configuration management through intuitive UI
- **Universal Installers**: Cross-platform installation scripts for Windows (`install.ps1`) and Unix/macOS (`install.sh`)
- **Service Management**: Background daemon with `--start`, `--stop`, `--restart`, `--uninstall` commands

#### User Interface
- **Modern Web Interface**: React-based frontend with FastAPI backend
- **Three Main Tabs**: Discovery, Chat, Reports
- **Settings Modal**: Comprehensive configuration for MCP server, LLM provider, and web server
- **Debug Mode**: Optional real-time debug window with WebSocket streaming
- **Dependencies Viewer**: Modal showing installed Python packages and versions

#### Quality & Reliability
- **Quality Assessment**: Intelligent scoring system for SPL query results
  - High (‚â•70): Immediately usable results
  - Moderate (50-69): Accept if actionable or continue refining
  - Low (<50): Force query refinement with format requirements
- **Timestamp Formatting Detection**: Prevents convergence during post-processing steps
- **Diversity Requirements**: SPL query generation with temperature 0.75 to ensure varied approaches
- **Error Handling**: Comprehensive error messages and debug logging

#### Developer Experience
- **Clean Codebase**: Removed unused modules (CLI, classification, recommendations, output)
- **Type Safety**: Pydantic models for configuration and API requests
- **Async/Await**: Modern async Python for efficient I/O operations
- **Documented Code**: Inline comments and clear function signatures

### Technical Details

#### Dependencies
- FastAPI 0.104.0+ (web framework)
- Uvicorn 0.24.0+ (ASGI server)
- Cryptography 41.0.0+ (encryption)
- PyYAML 6.0+ (configuration)
- HTTPX 0.24.0+ (HTTP client)
- AIOHTTP 3.9.0+ (async HTTP)
- OpenAI 1.0.0+ (LLM integration)
- Python 3.8+ (runtime)

#### Architecture
- **Port**: 8003 (configurable)
- **Protocol**: HTTP + WebSocket
- **Storage**: Encrypted config file (`config.encrypted`)
- **Logs**: `dt4sms.log` (when run as service)
- **PID**: `.dt4sms.pid` (service mode)

### Installation
```bash
# Windows
.\install.ps1

# Unix/macOS
./install.sh
```

### Configuration
Access settings at `http://localhost:8003` ‚Üí ‚öôÔ∏è Settings icon

Required configuration:
- MCP Server endpoint and bearer token
- LLM API key and model selection

### Known Limitations
- Discovery mode UI in progress (chat mode fully functional)
- Single LLM provider per session (configurable via settings)
- Debug mode secrets sanitization (filters common patterns but may not catch all)

### Future Roadmap (v1.1+)
- Intent alignment validation using semantic similarity
- Enhanced SPL query generation with multi-pass refinement
- Discovery result caching with differential updates
- Support for multiple LLM providers simultaneously
- Export chat history and SPL queries

---

## Release Notes

**v1.0.0** represents the culmination of extensive development and testing to create a production-ready Splunk admin assistant. The focus was on reliability, security, and user experience.

### Highlights
- ‚úÖ **Zero plaintext secrets**: All credentials encrypted at rest
- ‚úÖ **One-command installation**: Universal installers for all platforms
- ‚úÖ **Intelligent query refinement**: Multi-turn reasoning with quality gates
- ‚úÖ **Debug transparency**: Optional debug mode for troubleshooting
- ‚úÖ **Enterprise-ready**: Service mode with proper daemon management

---

[1.0.0]: https://github.com/LeiterConsulting/splunk-discovery-tool/releases/tag/v1.0.0
